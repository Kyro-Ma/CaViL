{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56227432-5f96-4a16-99ed-3c48a6acefc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_MODEL_NAME: llava-hf/llava-v1.6-mistral-7b-hf\n",
      "VISION_ADAPTER_DIR: ./out_distilled/Automotive/vision_lora_adapter_best\n",
      "LM_ADAPTER_DIR: ./out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Automotive.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Automotive\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Automotive/test.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HF_HOME\"] = \"/root/autodl-tmp/cache/\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"TMPDIR\"]=\"/root/autodl-tmp/tmp\"\n",
    "os.environ[\"TORCH_HOME\"]=\"/root/autodl-tmp/torch\"\n",
    "os.environ[\"PYTHONDONTWRITEBYTECODE\"]=\"1\"\n",
    "\n",
    "\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, LlavaNextForConditionalGeneration\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---- Config ----\n",
    "CATEGORY = \"Automotive\"\n",
    "CANDIDATE_TYPE = \"candidates_st\"\n",
    "BASE_MODEL_NAME = \"llava-hf/llava-v1.6-mistral-7b-hf\"\n",
    "VISION_ADAPTER_DIR = f\"./out_distilled/{CATEGORY}/vision_lora_adapter_best\"\n",
    "LM_ADAPTER_DIR = f\"./out_finetuned/{CATEGORY}/prompt_tuning/trained_lora_adapter\"\n",
    "FINETUNE_OUTPUT_DIR = f\"./test_out/{CATEGORY}\"\n",
    "#DATA_ROOT = Path(\"../data\")\n",
    "DATA_ROOT = Path(\"/root/autodl-tmp/lavic/data\")\n",
    "ITEM_META_PATH = DATA_ROOT / f\"item2meta_train_{CATEGORY}.with_desc.json\"\n",
    "IMAGE_DIR = DATA_ROOT / \"train_images\" / CATEGORY\n",
    "TEST_DATA_PATH = DATA_ROOT / CATEGORY / \"test.jsonl\"\n",
    "BATCH_SIZE = 1\n",
    "MAX_LENGTH = 2048\n",
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float16 if DEVICE == \"cuda:1\" else torch.float32\n",
    "\n",
    "print(\"BASE_MODEL_NAME:\", BASE_MODEL_NAME)\n",
    "print(\"VISION_ADAPTER_DIR:\", VISION_ADAPTER_DIR)\n",
    "print(\"LM_ADAPTER_DIR:\", LM_ADAPTER_DIR)\n",
    "print(\"ITEM_META_PATH:\", ITEM_META_PATH)\n",
    "print(\"IMAGE_DIR:\", IMAGE_DIR)\n",
    "print(\"TEST_DATA_PATH:\", TEST_DATA_PATH)\n",
    "\n",
    "IMAGE_TOKENS = [\n",
    "    \"<ItemImageEmb1>\", \"<ItemImageEmb2>\", \"<ItemImageEmb3>\",\n",
    "    \"<ItemImageEmb4>\", \"<ItemImageEmb5>\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0f6ada-befb-4943-8308-c2fb7e3ba23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: /root/autodl-tmp/lavic\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Automotive.with_desc.json\n",
      "resolved: /root/autodl-tmp/lavic/data/item2meta_train_Automotive.with_desc.json\n",
      "exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(\"cwd:\", Path.cwd())\n",
    "print(\"ITEM_META_PATH:\", ITEM_META_PATH)\n",
    "print(\"resolved:\", ITEM_META_PATH.resolve())\n",
    "print(\"exists:\", ITEM_META_PATH.exists())\n",
    "\n",
    "DATA_ROOT = Path(\"/root/autodl-tmp/lavic/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15722407-210f-4eef-a5b4-384b10e01da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_item_meta(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    rows = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "def evaluate_recall_at_k(recommended_ids, gt_items, k=1):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "    for rec_id, gts in zip(recommended_ids, gt_items):\n",
    "        for gt in gts:\n",
    "            if rec_id is not None and rec_id == gt:\n",
    "                hits += 1\n",
    "            total += 1\n",
    "    recall = hits / total if total > 0 else 0.0\n",
    "    return recall\n",
    "\n",
    "def check_validity(file_path, model_key):\n",
    "    candidates_key = f\"candidates_{model_key}\"\n",
    "    recommended_key = f\"recommended_{model_key}\"\n",
    "    total = 0\n",
    "    valid = 0\n",
    "    invalid_entries = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for idx, line in enumerate(f, 1):\n",
    "            try:\n",
    "                data = json.loads(line.strip())\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            recommended = data.get(recommended_key, None)\n",
    "            candidates = data.get(candidates_key, [])\n",
    "            total += 1\n",
    "            if recommended in candidates:\n",
    "                valid += 1\n",
    "            else:\n",
    "                invalid_entries.append({\n",
    "                    \"line_number\": idx,\n",
    "                    \"recommended_id\": recommended,\n",
    "                    \"candidates\": candidates\n",
    "                })\n",
    "    validity = valid / total if total > 0 else 0.0\n",
    "    return validity, invalid_entries, total\n",
    "\n",
    "def prepare_candidate_info(candidates, item_meta, image_dir, default_image):\n",
    "    candidate_info = []\n",
    "    for cid in candidates:\n",
    "        title = item_meta.get(cid, {}).get('title', 'No Title')\n",
    "        image_path = image_dir / f\"{cid}_0.jpg\"\n",
    "        if image_path.exists():\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        else:\n",
    "            image = default_image\n",
    "        candidate_info.append({\n",
    "            'id': cid,\n",
    "            'title': title,\n",
    "            'image': image\n",
    "        })\n",
    "    return candidate_info\n",
    "\n",
    "CONV_CHARS_PER_TOKEN = 4\n",
    "\n",
    "def build_prompt(conversation_text, candidates_info, max_conv_chars=None):\n",
    "    if max_conv_chars is not None and len(conversation_text) > max_conv_chars:\n",
    "        head_len = max_conv_chars // 2\n",
    "        tail_len = max_conv_chars - head_len\n",
    "        conversation_text = (\n",
    "            conversation_text[:head_len]\n",
    "            + \"\\n...[TRUNCATED]...\\n\"\n",
    "            + conversation_text[-tail_len:]\n",
    "        )\n",
    "    prompt = (\n",
    "        \"You are an AI assistant specialized in providing personalized product recommendations based on user conversations. \"\n",
    "        \"You are given a conversation between a user seeking recommendation (denoted by <submission>) and other users providing comments (denoted by <comment>). \"\n",
    "        \"You are also given a set of candidate products with their IDs, titles and images formatted as \\\"ID: title\\\" followed by an image. \"\n",
    "        \"Among the candidates, recommend the most relevant product to the seeker. \"\n",
    "        \"Only reply with its ID, and don't say anything else.\\n\\n\"\n",
    "        f\"Conversation:\\n{conversation_text}\\n\\n\"\n",
    "        \"Candidates:\\n\"\n",
    "    )\n",
    "    for candidate in candidates_info:\n",
    "        cid = candidate['id']\n",
    "        title = candidate['title']\n",
    "        prompt += f\"{cid}: {title}\\n\"\n",
    "        prompt += \"\".join(IMAGE_TOKENS) + \"\\n\"\n",
    "    prompt += \"\\nAssistant:\"\n",
    "    return prompt\n",
    "\n",
    "class RecommendationDataset(Dataset):\n",
    "    def __init__(self, data, item_meta, image_dir, candidate_type, max_conv_chars=None):\n",
    "        self.data = data\n",
    "        self.item_meta = item_meta\n",
    "        self.image_dir = image_dir\n",
    "        self.candidate_type = candidate_type\n",
    "        self.default_image = Image.new('RGB', (336, 336), color=(255, 255, 255))\n",
    "        if max_conv_chars is None:\n",
    "            max_conv_chars = MAX_LENGTH * CONV_CHARS_PER_TOKEN\n",
    "        self.max_conv_chars = max_conv_chars\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        conversation_text = entry.get('context', '')\n",
    "        gt_items = entry.get('gt_items', [])\n",
    "        candidates = entry.get(self.candidate_type, [])\n",
    "        candidate_info = prepare_candidate_info(candidates, self.item_meta, self.image_dir, self.default_image)\n",
    "        prompt = build_prompt(conversation_text, candidate_info, max_conv_chars=self.max_conv_chars)\n",
    "        images = [c['image'] for c in candidate_info]\n",
    "        return {\n",
    "            'prompt': prompt,\n",
    "            'images': images,\n",
    "            'gt_items': gt_items,\n",
    "            'entry_idx': idx\n",
    "        }\n",
    "\n",
    "class DataCollatorForLLaVA:\n",
    "    def __init__(self, processor, tokenizer, max_length):\n",
    "        self.processor = processor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.image_token_ids = [\n",
    "            self.tokenizer.convert_tokens_to_ids(tk) for tk in IMAGE_TOKENS\n",
    "        ]\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        prompts = [item['prompt'] for item in batch]\n",
    "        images_per_sample = [item['images'] for item in batch]\n",
    "\n",
    "        tokenized = self.tokenizer(\n",
    "            prompts,\n",
    "            add_special_tokens=True,\n",
    "            padding=False,\n",
    "            truncation=False,\n",
    "        )\n",
    "\n",
    "        input_ids_list = []\n",
    "        for prompt_ids in tokenized['input_ids']:\n",
    "            prompt_ids = list(prompt_ids)\n",
    "            if len(prompt_ids) > self.max_length:\n",
    "                bos_id = self.tokenizer.bos_token_id\n",
    "                if bos_id is not None and prompt_ids[0] == bos_id:\n",
    "                    prompt_ids = [bos_id] + prompt_ids[-(self.max_length - 1):]\n",
    "                else:\n",
    "                    prompt_ids = prompt_ids[-self.max_length:]\n",
    "            input_ids_list.append(prompt_ids)\n",
    "\n",
    "        max_len = max(len(ids) for ids in input_ids_list)\n",
    "        pad_id = self.tokenizer.pad_token_id\n",
    "        input_ids = torch.full((len(input_ids_list), max_len), pad_id, dtype=torch.long)\n",
    "        attention_mask = torch.zeros((len(input_ids_list), max_len), dtype=torch.long)\n",
    "\n",
    "        for i, ids in enumerate(input_ids_list):\n",
    "            seq_len = len(ids)\n",
    "            input_ids[i, :seq_len] = torch.tensor(ids, dtype=torch.long)\n",
    "            attention_mask[i, :seq_len] = 1\n",
    "\n",
    "        image_token_mask = torch.zeros_like(input_ids, dtype=torch.bool)\n",
    "        for b_idx in range(input_ids.size(0)):\n",
    "            for tid in self.image_token_ids:\n",
    "                positions = (input_ids[b_idx] == tid).nonzero(as_tuple=False).squeeze(-1)\n",
    "                image_token_mask[b_idx, positions] = True\n",
    "\n",
    "        all_images = []\n",
    "        for imgs in images_per_sample:\n",
    "            all_images.extend(imgs)\n",
    "\n",
    "        if all_images:\n",
    "            images_processed = self.processor.image_processor(all_images, return_tensors='pt')\n",
    "            images_tensor = images_processed['pixel_values']\n",
    "        else:\n",
    "            images_tensor = None\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'images': images_tensor,\n",
    "            'image_token_mask': image_token_mask\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e628df36-f7d5-4866-9325-bba960a9b3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbccd4f0b14e44429014bd6581e89051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# Load base model + processor\n",
    "base_model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "    BASE_MODEL_NAME,\n",
    "    torch_dtype=DTYPE,\n",
    "    local_files_only=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(BASE_MODEL_NAME, local_files_only=True)\n",
    "tokenizer = processor.tokenizer\n",
    "\n",
    "# Add special tokens\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": IMAGE_TOKENS})\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Merge vision adapter\n",
    "if VISION_ADAPTER_DIR and Path(VISION_ADAPTER_DIR).is_dir():\n",
    "    base_model = PeftModel.from_pretrained(base_model, VISION_ADAPTER_DIR, local_files_only=True)\n",
    "    base_model = base_model.merge_and_unload()\n",
    "    base_model.to(DEVICE)\n",
    "\n",
    "model = base_model\n",
    "if LM_ADAPTER_DIR and Path(LM_ADAPTER_DIR).is_dir():\n",
    "    model = PeftModel.from_pretrained(base_model, LM_ADAPTER_DIR, local_files_only=True)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Data\n",
    "item_meta = load_item_meta(ITEM_META_PATH)\n",
    "test_data = load_jsonl(TEST_DATA_PATH)\n",
    "test_ds = RecommendationDataset(test_data, item_meta, IMAGE_DIR, CANDIDATE_TYPE)\n",
    "collator = DataCollatorForLLaVA(processor, tokenizer, MAX_LENGTH)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb686f45-1d34-4928-ba47-77de224472b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ST_MODEL_NAME: /root/autodl-tmp/cache/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/c9745ed1d9f207416be6d2e6f8de32d1f16199bf\n",
      "[DEBUG] Offline mode: HF_HUB_OFFLINE=1, TRANSFORMERS_OFFLINE=1\n",
      "[DEBUG] VISION_TEMPLATE: /root/autodl-tmp/lavic/src/out_distilled/{category}/lora_adapter_best\n",
      "[DEBUG] LM_TEMPLATE: /root/autodl-tmp/lavic/src/out_finetuned/{category}/prompt_tuning/trained_lora_adapter\n",
      "[DEBUG] Router categories: 26\n",
      "[DEBUG] ST model dim: 384\n",
      "[DEBUG] Router loaded\n",
      "[DEBUG] Adapter pairs found: 26\n",
      "[DEBUG] FALLBACK_CATEGORY: Appliances\n"
     ]
    }
   ],
   "source": [
    "### Batch evaluate all categories with the last cell's logic\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn as nn\n",
    "\n",
    "CATEGORY_LIST = [\n",
    "    \"amazon_home\",\n",
    "    \"amazon_fashion\",\n",
    "    \"all_beauty\",\n",
    "    \"Appliances\",\n",
    "    \"Arts_Crafts_and_Sewing\",\n",
    "    \"Automotive\",\n",
    "    \"Baby_Products\",\n",
    "    \"Books\",\n",
    "    \"CDs_and_Vinyl\",\n",
    "    \"Cell_Phones_and_Accessories\",\n",
    "    \"Digital_Music\",\n",
    "    \"Electronics\",\n",
    "    \"Grocery_and_Gourmet_Food\",\n",
    "    \"Handmade_Products\",\n",
    "    \"Health\",\n",
    "    \"Industrial_and_Scientific\",\n",
    "    \"Kindle_Store\",\n",
    "    \"Movies_and_TV\",\n",
    "    \"Musical_Instruments\",\n",
    "    \"Office_Products\",\n",
    "    \"Patio_Lawn_and_Garden\",\n",
    "    \"Pet_Supplies\",\n",
    "    \"Software\",\n",
    "    \"Sports_and_Outdoors\",\n",
    "    \"Toys_and_Games\",\n",
    "    \"Video_Games\",\n",
    "]\n",
    "\n",
    "# Force offline to avoid any downloads\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "\n",
    "# Gate router paths (from MoLoRA_Gating_lllm (1).ipynb)\n",
    "GATE_CKPT_DIR = Path(\"/root/autodl-tmp/cache/llmSimpleRouter\")\n",
    "GATE_ROUTER_PATH = GATE_CKPT_DIR / \"gate_router.pt\"\n",
    "GATE_LABEL_MAP_PATH = GATE_CKPT_DIR / \"gate_label_mapping.json\"\n",
    "ST_MAX_LENGTH = 256\n",
    "ST_MODEL_NAME = \"/root/autodl-tmp/cache/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/c9745ed1d9f207416be6d2e6f8de32d1f16199bf\"\n",
    "if not Path(ST_MODEL_NAME).is_dir():\n",
    "    raise FileNotFoundError(f\"ST model path not found: {ST_MODEL_NAME}\")\n",
    "print(\"[DEBUG] ST_MODEL_NAME:\", ST_MODEL_NAME)\n",
    "\n",
    "TOPK = 3\n",
    "CONF_THRESHOLD = 0.0  # set >0 to drop low-conf router picks\n",
    "FALLBACK_CATEGORY = None  # None => first available\n",
    "\n",
    "# Absolute path templates (CATEGORY will be replaced)\n",
    "VISION_TEMPLATE = \"/root/autodl-tmp/lavic/src/out_distilled/{category}/lora_adapter_best\"\n",
    "LM_TEMPLATE = \"/root/autodl-tmp/lavic/src/out_finetuned/{category}/prompt_tuning/trained_lora_adapter\"\n",
    "\n",
    "print(\"[DEBUG] Offline mode: HF_HUB_OFFLINE=1, TRANSFORMERS_OFFLINE=1\")\n",
    "print(\"[DEBUG] VISION_TEMPLATE:\", VISION_TEMPLATE)\n",
    "print(\"[DEBUG] LM_TEMPLATE:\", LM_TEMPLATE)\n",
    "\n",
    "class SimpleRouter(nn.Module):\n",
    "    def __init__(self, hidden_size, num_adapters):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(hidden_size, num_adapters))\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "if BATCH_SIZE != 1:\n",
    "    raise ValueError(\"Top-3 router evaluation assumes BATCH_SIZE=1 (image placement).\")\n",
    "\n",
    "if not GATE_ROUTER_PATH.exists() or not GATE_LABEL_MAP_PATH.exists():\n",
    "    raise FileNotFoundError(\"Missing gate router or label mapping.\")\n",
    "\n",
    "with GATE_LABEL_MAP_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    label_map = json.load(f)\n",
    "sorted_indices = sorted(int(i) for i in label_map.keys())\n",
    "gate_categories = [label_map[str(i)] for i in sorted_indices]\n",
    "print(\"[DEBUG] Router categories:\", len(gate_categories))\n",
    "\n",
    "st_model = SentenceTransformer(ST_MODEL_NAME, device=DEVICE, cache_folder=os.environ.get(\"HF_HOME\"), local_files_only=True)\n",
    "st_model.max_seq_length = ST_MAX_LENGTH\n",
    "embed_dim = st_model.get_sentence_embedding_dimension()\n",
    "print(\"[DEBUG] ST model dim:\", embed_dim)\n",
    "\n",
    "router = SimpleRouter(hidden_size=embed_dim, num_adapters=len(gate_categories)).to(DEVICE).to(DTYPE)\n",
    "router.load_state_dict(torch.load(GATE_ROUTER_PATH, map_location=DEVICE))\n",
    "router.eval()\n",
    "print(\"[DEBUG] Router loaded\")\n",
    "\n",
    "# Discover adapter pairs per category\n",
    "category_to_adapters = {}\n",
    "for cat in gate_categories:\n",
    "    v_dir = Path(VISION_TEMPLATE.format(category=cat))\n",
    "    if v_dir.is_dir():\n",
    "        category_to_adapters[cat] = {\n",
    "            \"vision\": str(v_dir),\n",
    "        }\n",
    "print(\"[DEBUG] Adapter pairs found:\", len(category_to_adapters))\n",
    "\n",
    "if not category_to_adapters:\n",
    "    raise RuntimeError(\"No valid (vision+lm) adapter pairs found.\")\n",
    "\n",
    "if FALLBACK_CATEGORY is None or FALLBACK_CATEGORY not in category_to_adapters:\n",
    "    FALLBACK_CATEGORY = sorted(category_to_adapters.keys())[0]\n",
    "print(\"[DEBUG] FALLBACK_CATEGORY:\", FALLBACK_CATEGORY)\n",
    "\n",
    "\n",
    "def evaluate_category(category: str) -> None:\n",
    "    global CATEGORY, ITEM_META_PATH, IMAGE_DIR, TEST_DATA_PATH, FINETUNE_OUTPUT_DIR\n",
    "\n",
    "    CATEGORY = category\n",
    "    LM_FIXED_DIR = Path(LM_TEMPLATE.format(category=CATEGORY))\n",
    "    if not LM_FIXED_DIR.is_dir():\n",
    "        raise FileNotFoundError(f\"LM LoRA not found for CATEGORY={CATEGORY}: {LM_FIXED_DIR}\")\n",
    "    print(\"[DEBUG] LM_FIXED_DIR:\", LM_FIXED_DIR)\n",
    "    ITEM_META_PATH = DATA_ROOT / f\"item2meta_train_{CATEGORY}.with_desc.json\"\n",
    "    IMAGE_DIR = DATA_ROOT / \"train_images\" / CATEGORY\n",
    "    TEST_DATA_PATH = DATA_ROOT / CATEGORY / \"test.jsonl\"\n",
    "    FINETUNE_OUTPUT_DIR = f\"./slora_test_out/{CATEGORY}\"\n",
    "\n",
    "    print(\"\\n========================================\")\n",
    "    print(f\"[DEBUG] Start category: {CATEGORY}\")\n",
    "    print(\"ITEM_META_PATH:\", ITEM_META_PATH)\n",
    "    print(\"IMAGE_DIR:\", IMAGE_DIR)\n",
    "    print(\"TEST_DATA_PATH:\", TEST_DATA_PATH)\n",
    "    print(\"FINETUNE_OUTPUT_DIR:\", FINETUNE_OUTPUT_DIR)\n",
    "    print(\"========================================\")\n",
    "\n",
    "    item_meta = load_item_meta(ITEM_META_PATH)\n",
    "    test_data = load_jsonl(TEST_DATA_PATH)\n",
    "    test_ds = RecommendationDataset(test_data, item_meta, IMAGE_DIR, CANDIDATE_TYPE)\n",
    "    collator = DataCollatorForLLaVA(processor, tokenizer, MAX_LENGTH)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda x: x)\n",
    "\n",
    "    # Pass 1: route top-3 for each sample\n",
    "    sample_top3 = []\n",
    "    category_to_samples = {cat: [] for cat in category_to_adapters.keys()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(test_loader, desc=f\"Routing {CATEGORY}\", unit=\"batch\"), 1):\n",
    "            entry_idx = batch[0].get('entry_idx', None)\n",
    "            if entry_idx is None:\n",
    "                raise ValueError(\"Missing entry_idx in batch.\")\n",
    "            context_text = test_data[entry_idx].get('context', '').strip()\n",
    "            emb = st_model.encode([context_text], convert_to_tensor=True, device=DEVICE, show_progress_bar=False)\n",
    "            emb = emb.to(DTYPE)\n",
    "            logits = router(emb)\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            top_probs, top_idx = torch.topk(probs, k=min(TOPK, probs.shape[-1]), dim=-1)\n",
    "\n",
    "            top_cats = []\n",
    "            top_confs = []\n",
    "            for i in range(top_idx.shape[-1]):\n",
    "                idx = int(top_idx[0, i].item())\n",
    "                cat = label_map.get(str(idx), None)\n",
    "                conf = float(top_probs[0, i].item())\n",
    "                if conf < CONF_THRESHOLD or cat not in category_to_adapters:\n",
    "                    continue\n",
    "                top_cats.append(cat)\n",
    "                top_confs.append(conf)\n",
    "\n",
    "            if not top_cats:\n",
    "                top_cats = [FALLBACK_CATEGORY]\n",
    "                top_confs = [1.0]\n",
    "\n",
    "            sample_top3.append({\n",
    "                \"top_cats\": top_cats,\n",
    "                \"top_confs\": top_confs,\n",
    "            })\n",
    "            for cat in top_cats:\n",
    "                category_to_samples[cat].append(entry_idx)\n",
    "\n",
    "    print(f\"[DEBUG] Routing complete for {CATEGORY}. Samples: {len(sample_top3)}\")\n",
    "\n",
    "    # Prepare aggregation containers\n",
    "    recommended_ids = [None] * len(test_data)\n",
    "    responses = [\"\"] * len(test_data)\n",
    "    ground_truths = [entry.get('gt_items', []) for entry in test_data]\n",
    "    selected_categories = [None] * len(test_data)\n",
    "    selected_confs = [None] * len(test_data)\n",
    "    selected_top3 = [None] * len(test_data)\n",
    "    selected_top3_confs = [None] * len(test_data)\n",
    "    selected_top3_recs = [None] * len(test_data)\n",
    "\n",
    "    score_maps = [None] * len(test_data)\n",
    "    resp_maps = [None] * len(test_data)\n",
    "\n",
    "    # Pass 2: process per category (load once)\n",
    "    for cat, sample_ids in category_to_samples.items():\n",
    "        if not sample_ids:\n",
    "            continue\n",
    "\n",
    "        v_dir = category_to_adapters[cat][\"vision\"]\n",
    "        l_dir = LM_FIXED_DIR\n",
    "        print(f\"[DEBUG] Load model for {cat}:\\n  vision={v_dir}\\n  lm={l_dir}\\n  samples={len(sample_ids)}\")\n",
    "\n",
    "        base = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "            BASE_MODEL_NAME,\n",
    "            torch_dtype=DTYPE,\n",
    "            local_files_only=True,\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # merge vision adapter\n",
    "        base = PeftModel.from_pretrained(base, v_dir, local_files_only=True)\n",
    "        base = base.merge_and_unload()\n",
    "        base = base.to(DEVICE)\n",
    "\n",
    "        # apply LM adapter\n",
    "        model = PeftModel.from_pretrained(base, l_dir, local_files_only=True).to(DEVICE)\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for entry_idx in tqdm(sample_ids, desc=f\"Evaluating {CATEGORY}->{cat}\", unit=\"sample\"):\n",
    "                batch = [test_ds[entry_idx]]\n",
    "                inputs = collator(batch)\n",
    "                input_ids = inputs['input_ids'].to(DEVICE)\n",
    "                attention_mask = inputs['attention_mask'].to(DEVICE)\n",
    "                image_token_mask = inputs['image_token_mask'].to(DEVICE)\n",
    "                images = inputs['images']\n",
    "\n",
    "                inputs_embeds = model.language_model.get_input_embeddings()(input_ids)\n",
    "                if images is not None:\n",
    "                    images = images.to(DEVICE, dtype=DTYPE)\n",
    "                    if images.dim() == 5:\n",
    "                        b_img, num_views, c, h, w = images.shape\n",
    "                        images_reshaped = images.view(-1, c, h, w)\n",
    "                    else:\n",
    "                        num_views = 1\n",
    "                        images_reshaped = images\n",
    "                    vision_outputs = model.vision_tower(images_reshaped, return_dict=False)\n",
    "                    cls_states = vision_outputs[0][:, 0, :]\n",
    "                    total_patches = cls_states.shape[0]\n",
    "                    expected_images = input_ids.size(0) * num_views\n",
    "                    if total_patches > expected_images:\n",
    "                        patches_per_image = total_patches // expected_images\n",
    "                        if total_patches % expected_images == 0 and patches_per_image > 1:\n",
    "                            cls_states = cls_states.view(expected_images, patches_per_image, -1).mean(dim=1)\n",
    "                    cls_states = cls_states.reshape(input_ids.size(0), num_views, -1)\n",
    "                    cls_states = model.multi_modal_projector(cls_states)\n",
    "                    for b_idx in range(input_ids.size(0)):\n",
    "                        positions = torch.nonzero(image_token_mask[b_idx], as_tuple=False).squeeze(-1)\n",
    "                        pos_count = min(len(positions), num_views)\n",
    "                        for i in range(pos_count):\n",
    "                            col = positions[i].item()\n",
    "                            inputs_embeds[b_idx, col, :] = cls_states[b_idx, i, :]\n",
    "\n",
    "                generated_ids = model.generate(\n",
    "                    inputs_embeds=inputs_embeds,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_new_tokens=10,\n",
    "                    num_beams=1,\n",
    "                    do_sample=False,\n",
    "                    pad_token_id=tokenizer.pad_token_id,\n",
    "                )\n",
    "                generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "                match = re.findall(r'\\bB[A-Z0-9]{9}\\b', generated_texts[0].strip())\n",
    "                rec_id = match[0][:10] if match else None\n",
    "\n",
    "                # init per-sample aggregation\n",
    "                if score_maps[entry_idx] is None:\n",
    "                    score_maps[entry_idx] = {}\n",
    "                    resp_maps[entry_idx] = {}\n",
    "                    selected_top3[entry_idx] = sample_top3[entry_idx][\"top_cats\"]\n",
    "                    selected_top3_confs[entry_idx] = sample_top3[entry_idx][\"top_confs\"]\n",
    "                    selected_categories[entry_idx] = sample_top3[entry_idx][\"top_cats\"][0]\n",
    "                    selected_confs[entry_idx] = sample_top3[entry_idx][\"top_confs\"][0]\n",
    "\n",
    "                # weight by router confidence for this category\n",
    "                top_cats = sample_top3[entry_idx][\"top_cats\"]\n",
    "                top_confs = sample_top3[entry_idx][\"top_confs\"]\n",
    "                conf = top_confs[top_cats.index(cat)] if cat in top_cats else 0.0\n",
    "\n",
    "                score_maps[entry_idx][rec_id] = score_maps[entry_idx].get(rec_id, 0.0) + conf\n",
    "                if rec_id not in resp_maps[entry_idx]:\n",
    "                    resp_maps[entry_idx][rec_id] = generated_texts[0]\n",
    "\n",
    "        del model\n",
    "        del base\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Final fusion per sample\n",
    "    for i in range(len(test_data)):\n",
    "        if score_maps[i] is None or not score_maps[i]:\n",
    "            recommended_ids[i] = None\n",
    "            responses[i] = \"\"\n",
    "            selected_top3_recs[i] = []\n",
    "            continue\n",
    "\n",
    "        best_rec_id = max(score_maps[i].items(), key=lambda kv: kv[1])[0]\n",
    "        recommended_ids[i] = best_rec_id\n",
    "        responses[i] = resp_maps[i].get(best_rec_id, \"\")\n",
    "        selected_top3_recs[i] = [None] * len(selected_top3[i])\n",
    "\n",
    "    recall = evaluate_recall_at_k(recommended_ids, ground_truths, k=1)\n",
    "    print(f\"[Test] Recall@1 ({CATEGORY}): {recall:.4f}\")\n",
    "\n",
    "    model_key = 'st' if CANDIDATE_TYPE == 'candidates_st' else 'gpt_large'\n",
    "    if model_key == 'st':\n",
    "        recommended_field = 'recommended_st'\n",
    "        response_field = 'response_st'\n",
    "    else:\n",
    "        recommended_field = f\"recommended_{model_key}\"\n",
    "        response_field = f\"response_{model_key}\"\n",
    "\n",
    "    out_file_name = f\"test_results_{CANDIDATE_TYPE}_router_top3_vl.jsonl\"\n",
    "    output_file_path = Path(FINETUNE_OUTPUT_DIR) / out_file_name\n",
    "    output_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with output_file_path.open('w', encoding='utf-8') as f:\n",
    "        for entry, rec_id, resp, sel_cat, sel_conf, top3, top3_confs in zip(\n",
    "            test_data, recommended_ids, responses, selected_categories, selected_confs,\n",
    "            selected_top3, selected_top3_confs\n",
    "        ):\n",
    "            entry[recommended_field] = rec_id\n",
    "            entry[response_field] = resp\n",
    "            entry['selected_category'] = sel_cat\n",
    "            entry['selected_confidence'] = sel_conf\n",
    "            entry['router_top3'] = top3\n",
    "            entry['router_top3_confidences'] = top3_confs\n",
    "            json.dump(entry, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "    validity, invalid_entries, total_count = check_validity(output_file_path, model_key)\n",
    "    print(f\"Validity@1 ({CATEGORY}): {validity:.4f}, invalid entries: {len(invalid_entries)} / {total_count}\")\n",
    "    print(f\"Test details saved to {output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6732dbe-b68e-46cd-b244-5e5220784279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Automotive\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Automotive.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Automotive\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Automotive/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Automotive\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Automotive: 100%|██████████| 152/152 [00:01<00:00, 94.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Automotive. Samples: 152\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49810707d50b420d87852224d7fc1ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Appliances: 100%|██████████| 7/7 [00:04<00:00,  1.58sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Arts_Crafts_and_Sewing:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Arts_Crafts_and_Sewing/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226ef888fc354927a1796b57ba147862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Arts_Crafts_and_Sewing: 100%|██████████| 3/3 [00:01<00:00,  1.63sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Automotive:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Automotive/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8350d927c32c430fbd40173f1a18305d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Automotive: 100%|██████████| 143/143 [01:25<00:00,  1.66sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Baby_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Baby_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f94bd299c52409e8e7ddf6b80a693d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Baby_Products: 100%|██████████| 2/2 [00:01<00:00,  1.73sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for CDs_and_Vinyl:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/CDs_and_Vinyl/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bb6934580646f6b62b1da59889ad08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->CDs_and_Vinyl: 100%|██████████| 2/2 [00:01<00:00,  1.73sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Cell_Phones_and_Accessories:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Cell_Phones_and_Accessories/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b358a7400aa468eb7130f19cc674859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Cell_Phones_and_Accessories: 100%|██████████| 15/15 [00:09<00:00,  1.60sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Electronics:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Electronics/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d18f487f7d452bbdb18806885e373d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Electronics: 100%|██████████| 40/40 [00:24<00:00,  1.66sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Grocery_and_Gourmet_Food:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Grocery_and_Gourmet_Food/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de62133d498405aa68e9d8a5afa07df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Grocery_and_Gourmet_Food: 100%|██████████| 1/1 [00:00<00:00,  1.79sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075c3506f40a4f299c597470620e3ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Handmade_Products: 100%|██████████| 1/1 [00:00<00:00,  1.53sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Health:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Health/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04ad4085ed1448d93a3a60422b9ae2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Health: 100%|██████████| 2/2 [00:01<00:00,  1.63sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Industrial_and_Scientific:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Industrial_and_Scientific/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6544e535216746579773634f6b5d0db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Industrial_and_Scientific: 100%|██████████| 34/34 [00:20<00:00,  1.66sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429debdbde644dd7b226ac7544be2dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Kindle_Store: 100%|██████████| 1/1 [00:00<00:00,  1.66sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221754f390c54d94b285a20783b8c606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Movies_and_TV: 100%|██████████| 1/1 [00:00<00:00,  1.61sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48fecc4675742019ec19f81a324cbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Musical_Instruments: 100%|██████████| 9/9 [00:05<00:00,  1.60sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Office_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Office_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f632ad25540045e9b77f92db778966cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Office_Products: 100%|██████████| 5/5 [00:03<00:00,  1.59sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Patio_Lawn_and_Garden:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Patio_Lawn_and_Garden/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3494a0c0df3b42d5a2d690621e2dceec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Patio_Lawn_and_Garden: 100%|██████████| 1/1 [00:00<00:00,  1.60sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e15c6f6e0a44c59fdac7453c751942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Pet_Supplies: 100%|██████████| 9/9 [00:05<00:00,  1.66sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Software:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Software/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d740c4b52ab4694878539ed04a90ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Software: 100%|██████████| 2/2 [00:01<00:00,  1.61sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Sports_and_Outdoors:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Sports_and_Outdoors/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1eb349f6b845218d9d76034aa7e57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Sports_and_Outdoors: 100%|██████████| 2/2 [00:01<00:00,  1.76sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede0b4135bb64e2f9457fec82718833c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->Video_Games: 100%|██████████| 3/3 [00:01<00:00,  1.51sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for all_beauty:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/all_beauty/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887346bca5264697af1b32aeb3fa7b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->all_beauty: 100%|██████████| 64/64 [00:38<00:00,  1.68sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_fashion:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_fashion/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8c1829b38e414b9da126aa24cf298d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->amazon_fashion: 100%|██████████| 25/25 [00:18<00:00,  1.39sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Automotive/prompt_tuning/trained_lora_adapter\n",
      "  samples=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b9b2523a424fdd901869150a226fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Automotive->amazon_home: 100%|██████████| 84/84 [01:07<00:00,  1.25sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Automotive): 0.0987\n",
      "Validity@1 (Automotive): 1.0000, invalid entries: 0 / 152\n",
      "Test details saved to slora_test_out/Automotive/test_results_candidates_st_router_top3_vl.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_category(\"Automotive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fce6da00-94d2-4e63-8ac4-a5b54654deb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: all_beauty\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_all_beauty.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/all_beauty\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/all_beauty/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/all_beauty\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing all_beauty: 100%|██████████| 772/772 [00:11<00:00, 65.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for all_beauty. Samples: 772\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7b1399e72b4ed6818ffc5097a63999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Appliances: 100%|██████████| 4/4 [00:03<00:00,  1.17sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Arts_Crafts_and_Sewing:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Arts_Crafts_and_Sewing/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3be3b7158943d1aa9ea338c4aaa23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Arts_Crafts_and_Sewing: 100%|██████████| 29/29 [00:23<00:00,  1.25sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Automotive:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Automotive/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8084bd4e5be46c0a56840fda59b6f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Automotive: 100%|██████████| 58/58 [00:48<00:00,  1.21sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Baby_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Baby_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d399aa8ed3d849f79a9f504418216f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Baby_Products: 100%|██████████| 22/22 [00:18<00:00,  1.19sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Books:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Books/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5699b8653314e389b0bf191a76b1371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Books: 100%|██████████| 1/1 [00:00<00:00,  1.20sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for CDs_and_Vinyl:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/CDs_and_Vinyl/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47eee40968d344c194ad6d718a9d8ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->CDs_and_Vinyl: 100%|██████████| 8/8 [00:06<00:00,  1.32sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Cell_Phones_and_Accessories:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Cell_Phones_and_Accessories/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2009039853c548ffb2c3d4b9d9ac5af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Cell_Phones_and_Accessories: 100%|██████████| 3/3 [00:02<00:00,  1.11sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Electronics:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Electronics/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0996212e2c8641149042067a3a5be14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Electronics: 100%|██████████| 12/12 [00:10<00:00,  1.13sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Grocery_and_Gourmet_Food:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Grocery_and_Gourmet_Food/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a55c77af09f42189b2cb0a246d39b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Grocery_and_Gourmet_Food: 100%|██████████| 52/52 [00:41<00:00,  1.24sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ebd5a2576e4b38bc690775e4c802ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Handmade_Products: 100%|██████████| 15/15 [00:12<00:00,  1.23sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Health:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Health/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93328f3db7db49ab9dc9a5388a411e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Health: 100%|██████████| 367/367 [04:40<00:00,  1.31sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Industrial_and_Scientific:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Industrial_and_Scientific/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bb4968fed643329cf0842bf8322773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Industrial_and_Scientific: 100%|██████████| 32/32 [00:21<00:00,  1.48sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec0325e10914413827704966d70aaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Kindle_Store: 100%|██████████| 14/14 [00:11<00:00,  1.20sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fbc8e7316240d29a094c7e9dbd821e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Movies_and_TV: 100%|██████████| 6/6 [00:04<00:00,  1.31sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f0e675e8ae49bab892bf9983544ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Musical_Instruments: 100%|██████████| 3/3 [00:02<00:00,  1.09sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Office_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Office_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d827fdd3944a8da0af96b4b26c3871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Office_Products: 100%|██████████| 16/16 [00:12<00:00,  1.26sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Patio_Lawn_and_Garden:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Patio_Lawn_and_Garden/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c809a1eb9ade46acbdad3a0b69fa1b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Patio_Lawn_and_Garden: 100%|██████████| 10/10 [00:07<00:00,  1.26sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc95be6d6aae458488c00bcc0296506a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Pet_Supplies: 100%|██████████| 38/38 [00:30<00:00,  1.25sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Software:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Software/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0411599c904464a794f05f05e07a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Software: 100%|██████████| 1/1 [00:00<00:00,  1.06sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Sports_and_Outdoors:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Sports_and_Outdoors/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b35c2fd73a46f69f7e8e681f1ee439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Sports_and_Outdoors: 100%|██████████| 24/24 [00:19<00:00,  1.21sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Toys_and_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Toys_and_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ee6be48e3e47e6969c5581338f340b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Toys_and_Games: 100%|██████████| 6/6 [00:04<00:00,  1.29sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7deb4f5c86403a819f960fcb0fa790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->Video_Games: 100%|██████████| 38/38 [00:27<00:00,  1.39sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for all_beauty:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/all_beauty/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9f0bf9cfcc4688a3ab086aa7751938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->all_beauty: 100%|██████████| 739/739 [07:37<00:00,  1.62sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_fashion:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_fashion/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62486080fa2145be90e1ba36e4a801ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->amazon_fashion: 100%|██████████| 374/374 [03:52<00:00,  1.61sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/all_beauty/prompt_tuning/trained_lora_adapter\n",
      "  samples=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c869ed46b5654d3fb86ba370858565ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating all_beauty->amazon_home: 100%|██████████| 444/444 [06:02<00:00,  1.23sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (all_beauty): 0.1067\n",
      "Validity@1 (all_beauty): 0.9883, invalid entries: 9 / 772\n",
      "Test details saved to slora_test_out/all_beauty/test_results_candidates_st_router_top3_vl.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_category(\"all_beauty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f9c00bc-1031-4e33-9754-03bedc789fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: amazon_fashion\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_amazon_fashion.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/amazon_fashion\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/amazon_fashion/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/amazon_fashion\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing amazon_fashion: 100%|██████████| 826/826 [00:11<00:00, 71.00batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for amazon_fashion. Samples: 826\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfdec2826e644f296b06628f85f9b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Appliances: 100%|██████████| 3/3 [00:02<00:00,  1.46sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Arts_Crafts_and_Sewing:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Arts_Crafts_and_Sewing/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c23c7b68cfc432098260e8b10e7a2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Arts_Crafts_and_Sewing: 100%|██████████| 170/170 [01:54<00:00,  1.48sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Automotive:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Automotive/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd5c65f6a694807bc46fc446ef61e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Automotive: 100%|██████████| 34/34 [00:25<00:00,  1.31sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Baby_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Baby_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7f92e506b94661a40aa45bc656eccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Baby_Products: 100%|██████████| 25/25 [00:20<00:00,  1.25sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for CDs_and_Vinyl:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/CDs_and_Vinyl/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a10c5a87c724fc5b7cbcc0ba938c42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->CDs_and_Vinyl: 100%|██████████| 24/24 [00:18<00:00,  1.29sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Cell_Phones_and_Accessories:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Cell_Phones_and_Accessories/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7645c43a73904361af561b65154f3c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Cell_Phones_and_Accessories: 100%|██████████| 30/30 [00:22<00:00,  1.31sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Digital_Music:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Digital_Music/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca02a24c64e460194015d056ecc0cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Digital_Music: 100%|██████████| 1/1 [00:00<00:00,  1.63sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Electronics:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Electronics/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc24611f930b4552932814e00d94fbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Electronics: 100%|██████████| 26/26 [00:15<00:00,  1.65sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Grocery_and_Gourmet_Food:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Grocery_and_Gourmet_Food/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de06958d938143edb0023e6deae141d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Grocery_and_Gourmet_Food: 100%|██████████| 10/10 [00:07<00:00,  1.27sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3350fe44e42e4481b7d8f9d602421388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Handmade_Products: 100%|██████████| 90/90 [01:12<00:00,  1.25sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Health:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Health/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757c5ae232384b7a892f67825298cd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Health: 100%|██████████| 11/11 [00:09<00:00,  1.20sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Industrial_and_Scientific:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Industrial_and_Scientific/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e8d157346e472283b27f0ee39a4b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Industrial_and_Scientific: 100%|██████████| 24/24 [00:18<00:00,  1.28sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a4055c595b4814a44d32989669160a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Kindle_Store: 100%|██████████| 21/21 [00:16<00:00,  1.25sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2480ceccb0b74c6fa7df458c8dba37cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Movies_and_TV: 100%|██████████| 32/32 [00:24<00:00,  1.29sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e4d2b66a154da0a33a4c0f8b2be6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Musical_Instruments: 100%|██████████| 42/42 [00:25<00:00,  1.64sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Office_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Office_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcf81c9e7c24d5183c29e6cf8311794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Office_Products: 100%|██████████| 78/78 [00:42<00:00,  1.83sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Patio_Lawn_and_Garden:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Patio_Lawn_and_Garden/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62a314f45b4422bb71af387830217ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Patio_Lawn_and_Garden: 100%|██████████| 3/3 [00:01<00:00,  1.66sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371e56d5eefd40ea8b29f43929668289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Pet_Supplies: 100%|██████████| 19/19 [00:11<00:00,  1.70sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Software:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Software/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54923e7c48064daa975581b7b1e5ac5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Software: 100%|██████████| 2/2 [00:01<00:00,  1.53sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Sports_and_Outdoors:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Sports_and_Outdoors/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3800fc6bfe34613a205714d96a07945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Sports_and_Outdoors: 100%|██████████| 230/230 [02:10<00:00,  1.76sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Toys_and_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Toys_and_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cd763e5f564db5b8202d963b491490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Toys_and_Games: 100%|██████████| 47/47 [00:26<00:00,  1.80sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c0e9325dba44e3aede7e079329bb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->Video_Games: 100%|██████████| 56/56 [00:32<00:00,  1.72sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for all_beauty:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/all_beauty/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280156dc234044239a74d96a2b58153c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->all_beauty: 100%|██████████| 450/450 [04:21<00:00,  1.72sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_fashion:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_fashion/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3f895cd0bc4bd6b15b39f435c0aafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->amazon_fashion: 100%|██████████| 781/781 [07:27<00:00,  1.74sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_fashion/prompt_tuning/trained_lora_adapter\n",
      "  samples=269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7078122db042dfa9d01fac40867c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_fashion->amazon_home: 100%|██████████| 269/269 [02:32<00:00,  1.76sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (amazon_fashion): 0.1242\n",
      "Validity@1 (amazon_fashion): 0.9879, invalid entries: 10 / 826\n",
      "Test details saved to slora_test_out/amazon_fashion/test_results_candidates_st_router_top3_vl.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_category(\"amazon_fashion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b53a8d4-eed7-4f4b-9759-5272f1736d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: amazon_home\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_amazon_home.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/amazon_home\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/amazon_home/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/amazon_home\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing amazon_home: 100%|██████████| 372/372 [00:04<00:00, 77.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for amazon_home. Samples: 372\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24760c8f7d5d4a24a61924ea571df219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Appliances: 100%|██████████| 52/52 [00:30<00:00,  1.70sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Arts_Crafts_and_Sewing:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Arts_Crafts_and_Sewing/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f2c52e9f244445915beb829b3d8e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Arts_Crafts_and_Sewing: 100%|██████████| 29/29 [00:17<00:00,  1.70sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Automotive:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Automotive/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92f4244ecac431e8f3fb6873b829f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Automotive: 100%|██████████| 32/32 [00:19<00:00,  1.67sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Baby_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Baby_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1321b0d24fe44f5fa0d7a63e348b1eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Baby_Products: 100%|██████████| 26/26 [00:15<00:00,  1.68sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Books:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Books/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a44a40a61b405ea722a363b12e98e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Books: 100%|██████████| 3/3 [00:01<00:00,  1.62sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for CDs_and_Vinyl:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/CDs_and_Vinyl/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fb1c253213412aa3d36123abf03e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->CDs_and_Vinyl: 100%|██████████| 5/5 [00:02<00:00,  1.72sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Cell_Phones_and_Accessories:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Cell_Phones_and_Accessories/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b39acafeacb418d9778e88780b05b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Cell_Phones_and_Accessories: 100%|██████████| 3/3 [00:01<00:00,  1.72sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Electronics:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Electronics/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e89e46e5c6411a8bf5d6487e3e0def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Electronics: 100%|██████████| 48/48 [00:28<00:00,  1.67sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Grocery_and_Gourmet_Food:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Grocery_and_Gourmet_Food/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ed1b5cc724458c9b7f745c79036987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Grocery_and_Gourmet_Food: 100%|██████████| 55/55 [00:32<00:00,  1.71sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae69baf129ef45eebcd51e698d612f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Handmade_Products: 100%|██████████| 17/17 [00:10<00:00,  1.67sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Health:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Health/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec41ef3dd6964925871f8dbafe9e9f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Health: 100%|██████████| 19/19 [00:11<00:00,  1.67sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Industrial_and_Scientific:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Industrial_and_Scientific/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f20d63787d6488dae6896773a0ea045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Industrial_and_Scientific: 100%|██████████| 79/79 [00:46<00:00,  1.71sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55db4c69b6b4c15b403f62f43d1404a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Kindle_Store: 100%|██████████| 10/10 [00:05<00:00,  1.69sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fc0a7c28474bed99dd3e0041ce9c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Movies_and_TV: 100%|██████████| 6/6 [00:03<00:00,  1.72sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb98434f9f44bc686962f14adc34030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Musical_Instruments: 100%|██████████| 12/12 [00:07<00:00,  1.71sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Office_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Office_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdae26d9766423f8857326c971af21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Office_Products: 100%|██████████| 28/28 [00:16<00:00,  1.68sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Patio_Lawn_and_Garden:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Patio_Lawn_and_Garden/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5e8210e6cd4cc8889db33d6fb037fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Patio_Lawn_and_Garden: 100%|██████████| 29/29 [00:17<00:00,  1.68sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba3ee1a65684ef19a2331f332f03019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Pet_Supplies: 100%|██████████| 51/51 [00:30<00:00,  1.67sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Sports_and_Outdoors:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Sports_and_Outdoors/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad02cb3ed12a4c51bddf73845b6c6e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Sports_and_Outdoors: 100%|██████████| 16/16 [00:09<00:00,  1.68sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Toys_and_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Toys_and_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483891050a5c471a9c72cce746eacfac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Toys_and_Games: 100%|██████████| 18/18 [00:10<00:00,  1.71sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2323550462074623b6071ef65f3bf688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->Video_Games: 100%|██████████| 16/16 [00:09<00:00,  1.64sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for all_beauty:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/all_beauty/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba31a3780c3141468e02c18367a8d53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->all_beauty: 100%|██████████| 137/137 [01:21<00:00,  1.69sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_fashion:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_fashion/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afed14c290a64866bc9701969b8f2203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->amazon_fashion: 100%|██████████| 112/112 [01:07<00:00,  1.67sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/amazon_home/prompt_tuning/trained_lora_adapter\n",
      "  samples=313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5349f6704d284fbdac529389db9ac826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating amazon_home->amazon_home: 100%|██████████| 313/313 [03:07<00:00,  1.67sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (amazon_home): 0.2695\n",
      "Validity@1 (amazon_home): 1.0000, invalid entries: 0 / 372\n",
      "Test details saved to slora_test_out/amazon_home/test_results_candidates_st_router_top3_vl.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_category(\"amazon_home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "640a63a3-2cf2-4485-948c-737b1b0ae8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Books\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Books.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Books\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Books/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Books\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Books: 100%|██████████| 472/472 [00:05<00:00, 79.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Books. Samples: 472\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7496cd1ba049d5b254189ebe804c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Appliances: 100%|██████████| 1/1 [00:00<00:00,  1.81sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Arts_Crafts_and_Sewing:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Arts_Crafts_and_Sewing/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba6a61359ea466aa4a068ed562fadae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Arts_Crafts_and_Sewing: 100%|██████████| 2/2 [00:01<00:00,  1.69sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Automotive:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Automotive/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a36f01bf3244ee80a976f0ce9e10a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Automotive: 100%|██████████| 1/1 [00:00<00:00,  1.75sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Baby_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Baby_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62f33df73294e3aa3259699f5e19e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Baby_Products: 100%|██████████| 14/14 [00:08<00:00,  1.63sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Books:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Books/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38efe666b034bafad40d8c7d4129827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Books: 100%|██████████| 466/466 [05:12<00:00,  1.49sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for CDs_and_Vinyl:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/CDs_and_Vinyl/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdaa8670e847453f862480b7ffa8e4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->CDs_and_Vinyl: 100%|██████████| 6/6 [00:04<00:00,  1.33sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Cell_Phones_and_Accessories:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Cell_Phones_and_Accessories/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4e2558404f4dcca99238aec0e0b15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Cell_Phones_and_Accessories: 100%|██████████| 2/2 [00:01<00:00,  1.25sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Digital_Music:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Digital_Music/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cbf3e7f4424a228317d051d5856a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Digital_Music: 100%|██████████| 4/4 [00:03<00:00,  1.22sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Electronics:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Electronics/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0518e7606f407e8c0c71f0f87ce245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Electronics: 100%|██████████| 29/29 [00:22<00:00,  1.28sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Grocery_and_Gourmet_Food:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Grocery_and_Gourmet_Food/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c315cba4d1c542908166419c9b0a75b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Grocery_and_Gourmet_Food: 100%|██████████| 4/4 [00:03<00:00,  1.16sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8e32c6abef48fb8b58629bcaad0552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Handmade_Products: 100%|██████████| 36/36 [00:28<00:00,  1.25sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Health:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Health/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d1578038d0474d9038df051eca388e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Health: 100%|██████████| 8/8 [00:06<00:00,  1.30sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88799afb78848e587f3bacd126face8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Kindle_Store: 100%|██████████| 467/467 [05:52<00:00,  1.32sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4bb077a35b414783c784e0f0368bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Movies_and_TV: 100%|██████████| 69/69 [00:54<00:00,  1.27sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bd8330d17e4068a54f01fdc35a74bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Musical_Instruments: 100%|██████████| 20/20 [00:15<00:00,  1.27sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Office_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Office_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f87c1c3dbf144638c7ab2dfb858e14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Office_Products: 100%|██████████| 21/21 [00:16<00:00,  1.29sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Patio_Lawn_and_Garden:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Patio_Lawn_and_Garden/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d3a5b8dbd2400281e87f26a3d52f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Patio_Lawn_and_Garden: 100%|██████████| 2/2 [00:01<00:00,  1.25sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df18e357f194460c91172fac75e5068f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Pet_Supplies: 100%|██████████| 7/7 [00:05<00:00,  1.33sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Software:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Software/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db20359d10114b949d0245f405fbab46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Software: 100%|██████████| 1/1 [00:00<00:00,  1.35sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Sports_and_Outdoors:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Sports_and_Outdoors/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f6df64719c4d8693a707bf90441c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Sports_and_Outdoors: 100%|██████████| 2/2 [00:01<00:00,  1.34sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Toys_and_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Toys_and_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e59ea77a3a340cf8702df173f95e9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Toys_and_Games: 100%|██████████| 8/8 [00:06<00:00,  1.24sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13551dfc1f66482e8d687f604d97f220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Video_Games: 100%|██████████| 224/224 [02:49<00:00,  1.32sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for all_beauty:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/all_beauty/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e687867e47984cb6a3ca67db7bd8c949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->all_beauty: 100%|██████████| 5/5 [00:03<00:00,  1.31sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_fashion:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_fashion/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8471ddb7dc48edafcd07eefd506aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->amazon_fashion: 100%|██████████| 10/10 [00:07<00:00,  1.28sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6805e5b1b6b44df6843a7f567d267cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->amazon_home: 100%|██████████| 7/7 [00:05<00:00,  1.29sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Books): 0.0318\n",
      "Validity@1 (Books): 0.3008, invalid entries: 330 / 472\n",
      "Test details saved to slora_test_out/Books/test_results_candidates_st_router_top3_vl.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_category(\"Books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d489259-61df-432a-a68c-0c18fb4004a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Toys_and_Games\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Toys_and_Games.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Toys_and_Games\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Toys_and_Games/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Toys_and_Games\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Toys_and_Games: 100%|██████████| 192/192 [00:02<00:00, 64.09batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Toys_and_Games. Samples: 192\n",
      "[DEBUG] Load model for Arts_Crafts_and_Sewing:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Arts_Crafts_and_Sewing/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bef7e16b02410488b0a05d8f462a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Arts_Crafts_and_Sewing: 100%|██████████| 3/3 [00:02<00:00,  1.25sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Automotive:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Automotive/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0956a3d37220412aba512cf037e05653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Automotive: 100%|██████████| 2/2 [00:01<00:00,  1.18sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Baby_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Baby_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da8a2a58423403aa7c8476867b2a9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Baby_Products: 100%|██████████| 11/11 [00:09<00:00,  1.22sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Books:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Books/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760cde6f12864e23b3ee18837a5d99e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Books: 100%|██████████| 1/1 [00:00<00:00,  1.06sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for CDs_and_Vinyl:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/CDs_and_Vinyl/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ffbff8fd244688a9e898b7191d056a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->CDs_and_Vinyl: 100%|██████████| 5/5 [00:04<00:00,  1.17sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Cell_Phones_and_Accessories:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Cell_Phones_and_Accessories/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e730c4f0b1d4f1f97698a15171c28b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Cell_Phones_and_Accessories: 100%|██████████| 1/1 [00:00<00:00,  1.18sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Electronics:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Electronics/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a55891a373540f09f61fd39f1cb2d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Electronics: 100%|██████████| 6/6 [00:04<00:00,  1.25sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a55156ca0b842798b24f12b7a799933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Handmade_Products: 100%|██████████| 41/41 [00:36<00:00,  1.14sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Industrial_and_Scientific:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Industrial_and_Scientific/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb6b2de673e44e68b283b975f0e16b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Industrial_and_Scientific: 100%|██████████| 6/6 [00:04<00:00,  1.26sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90402b7bbbef4bd2b24b2b567f7410db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Kindle_Store: 100%|██████████| 48/48 [00:33<00:00,  1.41sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d784988e614637bcf9b84c9daf4899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Movies_and_TV: 100%|██████████| 29/29 [00:20<00:00,  1.44sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869f9fd5c1c84178a2401cb719cc5eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Musical_Instruments: 100%|██████████| 5/5 [00:03<00:00,  1.52sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Office_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Office_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe3e9fd1c9344638897473b7c9f7edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Office_Products: 100%|██████████| 15/15 [00:10<00:00,  1.45sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee51751301354893918849d3c1903ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Pet_Supplies: 100%|██████████| 5/5 [00:03<00:00,  1.45sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Sports_and_Outdoors:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Sports_and_Outdoors/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b866b79fb84dadae7abfe6bb0b7f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Sports_and_Outdoors: 100%|██████████| 7/7 [00:04<00:00,  1.58sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Toys_and_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Toys_and_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa177503d6e48a3aac39539b1b303d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Toys_and_Games: 100%|██████████| 183/183 [02:35<00:00,  1.17sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfa6cd9c32443b7b7f93b6eff50c5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Video_Games: 100%|██████████| 139/139 [02:00<00:00,  1.15sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for all_beauty:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/all_beauty/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75ec3489f76405ba0a93b4e7d404c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->all_beauty: 100%|██████████| 2/2 [00:01<00:00,  1.15sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_fashion:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_fashion/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b41e4fadd3476e8a40826ce0023cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->amazon_fashion: 100%|██████████| 41/41 [00:33<00:00,  1.21sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070931d6d1b24300b69934af65d7ee82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->amazon_home: 100%|██████████| 26/26 [00:20<00:00,  1.25sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Toys_and_Games): 0.3229\n",
      "Validity@1 (Toys_and_Games): 1.0000, invalid entries: 0 / 192\n",
      "Test details saved to slora_test_out/Toys_and_Games/test_results_candidates_st_router_top3_vl.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_category(\"Toys_and_Games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23f77a6b-53ce-45cb-9842-ec769cf25612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Appliances\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Appliances.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Appliances\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Appliances/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Appliances\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Appliances: 100%|██████████| 230/230 [00:03<00:00, 71.14batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Appliances. Samples: 230\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1e5d5ff59e4f67b973462a5bf3157b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Appliances: 100%|██████████| 226/226 [02:41<00:00,  1.40sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Arts_Crafts_and_Sewing:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Arts_Crafts_and_Sewing/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d845a02f64c04725b87569a9016cfdca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Arts_Crafts_and_Sewing: 100%|██████████| 5/5 [00:04<00:00,  1.23sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Automotive:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Automotive/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02f99de992e4567b2054b44e29c880a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Automotive: 100%|██████████| 36/36 [00:28<00:00,  1.26sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Baby_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Baby_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20110832e924b8688c17a97bd218fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Baby_Products: 100%|██████████| 52/52 [00:41<00:00,  1.24sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Cell_Phones_and_Accessories:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Cell_Phones_and_Accessories/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3cd4602e23461d879327db976ec48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Cell_Phones_and_Accessories: 100%|██████████| 4/4 [00:03<00:00,  1.31sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Electronics:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Electronics/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e198d031f24df1a23658f9935074d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Electronics: 100%|██████████| 46/46 [00:36<00:00,  1.24sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Grocery_and_Gourmet_Food:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Grocery_and_Gourmet_Food/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c05e45f87a4f27a808d1f6b6a90934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Grocery_and_Gourmet_Food: 100%|██████████| 3/3 [00:02<00:00,  1.22sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcdd385f53149ecbf8ae5a3942c1c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Handmade_Products: 100%|██████████| 3/3 [00:02<00:00,  1.15sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Health:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Health/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230af5fb10df496fb7cf31a41ce989ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Health: 100%|██████████| 1/1 [00:00<00:00,  1.22sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Industrial_and_Scientific:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Industrial_and_Scientific/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ff93764a4f4be0adbc31638ecccba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Industrial_and_Scientific: 100%|██████████| 54/54 [00:43<00:00,  1.24sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff35d53690404d8baaa0a62262e39e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Musical_Instruments: 100%|██████████| 1/1 [00:00<00:00,  1.34sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Office_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Office_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf45eaa3feb4572a876c6d4be5702f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Office_Products: 100%|██████████| 1/1 [00:00<00:00,  1.12sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99fdf30cb28b49068ff4a7d7073de80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Pet_Supplies: 100%|██████████| 9/9 [00:07<00:00,  1.20sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Software:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Software/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ddc1f01f564cf589de3abd6901ff96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Software: 100%|██████████| 2/2 [00:01<00:00,  1.21sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Sports_and_Outdoors:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Sports_and_Outdoors/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad603428a11d4e33befe86cdc1e0314f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Sports_and_Outdoors: 100%|██████████| 4/4 [00:03<00:00,  1.11sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for all_beauty:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/all_beauty/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd628c27402d4b3bb9ec7cdcfae7f697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->all_beauty: 100%|██████████| 13/13 [00:10<00:00,  1.22sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_fashion:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_fashion/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa1410dbfa74ac7a7f019b42d3bf33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->amazon_fashion: 100%|██████████| 8/8 [00:06<00:00,  1.29sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcc7c33b9394124b5d5c6a22972f0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->amazon_home: 100%|██████████| 222/222 [02:42<00:00,  1.37sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Appliances): 0.3478\n",
      "Validity@1 (Appliances): 0.9957, invalid entries: 1 / 230\n",
      "Test details saved to slora_test_out/Appliances/test_results_candidates_st_router_top3_vl.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_category(\"Appliances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7e55d-7ff1-4fb0-ad3d-a308f213186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#amz are in new_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a71d109b-70a9-4e2f-bfa7-6ea5c5bd9755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SWEEP] category=Books CONF_THRESHOLD=0.3\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Books\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Books.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Books\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Books/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Books\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Books: 100%|██████████| 472/472 [00:05<00:00, 88.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Books. Samples: 472\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8580fb9e60c41b19d21775d91bc0ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Appliances: 100%|██████████| 3/3 [00:01<00:00,  1.72sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Books:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Books/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792940d5210a46ebb69453f4ace317e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Books: 100%|██████████| 391/391 [03:44<00:00,  1.74sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for CDs_and_Vinyl:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/CDs_and_Vinyl/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557b657c31db421a961bb6f8112c9a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->CDs_and_Vinyl: 100%|██████████| 1/1 [00:00<00:00,  1.66sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36585dbd794a41eeb415c5afd71d42e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Handmade_Products: 100%|██████████| 2/2 [00:01<00:00,  1.80sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ffd3b23f00403f986ebe76219a9eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Kindle_Store: 100%|██████████| 242/242 [02:15<00:00,  1.79sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89013657df614ac5ad43dfbe1cb82abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Movies_and_TV: 100%|██████████| 1/1 [00:00<00:00,  1.74sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f84ba6c29e45a596dd1b9ca8030a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Musical_Instruments: 100%|██████████| 3/3 [00:01<00:00,  1.66sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f2a48c8768422791f7cc7ca992e1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Pet_Supplies: 100%|██████████| 2/2 [00:01<00:00,  1.71sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f16f17c66c7450f8ede7680417c8475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Video_Games: 100%|██████████| 6/6 [00:03<00:00,  1.81sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_fashion:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_fashion/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428cadffc3b841e9af8a25644175b799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->amazon_fashion: 100%|██████████| 1/1 [00:00<00:00,  1.79sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b509cef7c1a45418def20592cc1a951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->amazon_home: 100%|██████████| 1/1 [00:00<00:00,  1.53sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Books): 0.0318\n",
      "Validity@1 (Books): 0.3008, invalid entries: 330 / 472\n",
      "Test details saved to slora_test_out/Books/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Books CONF_THRESHOLD=0.4\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Books\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Books.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Books\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Books/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Books\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Books: 100%|██████████| 472/472 [00:05<00:00, 88.99batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Books. Samples: 472\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab33968741944f294f5817660da9426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Appliances: 100%|██████████| 6/6 [00:03<00:00,  1.74sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Books:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Books/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d281fa31e1b4be2822514e6a8d99673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Books: 100%|██████████| 352/352 [03:18<00:00,  1.77sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for CDs_and_Vinyl:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/CDs_and_Vinyl/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abf0da493a74badb5a488aeb71189d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->CDs_and_Vinyl: 100%|██████████| 1/1 [00:00<00:00,  1.77sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e2a85b55ac4d5a8a421865c09c41cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Handmade_Products: 100%|██████████| 1/1 [00:00<00:00,  1.66sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9153edeba0f8425ba35fabe17eedfaec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Kindle_Store: 100%|██████████| 178/178 [01:39<00:00,  1.78sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a447b0f2874db2a7529b8bdfb48a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Movies_and_TV: 100%|██████████| 1/1 [00:00<00:00,  1.78sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716592285083455fa60a941372abbd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Musical_Instruments: 100%|██████████| 1/1 [00:00<00:00,  1.62sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57236849c8349e79de4c5d7bf6e025c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Pet_Supplies: 100%|██████████| 1/1 [00:00<00:00,  1.65sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027557712abd4d3a9967e18aed1e104d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Video_Games: 100%|██████████| 6/6 [00:03<00:00,  1.69sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_fashion:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_fashion/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf7d0c0479246eb9e8f99586dd719b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->amazon_fashion: 100%|██████████| 1/1 [00:00<00:00,  1.73sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Books): 0.0318\n",
      "Validity@1 (Books): 0.3008, invalid entries: 330 / 472\n",
      "Test details saved to slora_test_out/Books/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Books CONF_THRESHOLD=0.5\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Books\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Books.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Books\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Books/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Books\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Books: 100%|██████████| 472/472 [00:05<00:00, 89.29batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Books. Samples: 472\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d264234849fb436c82a67bf926579ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Appliances: 100%|██████████| 40/40 [00:22<00:00,  1.81sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Books:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Books/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db066bbaa9c44859a12cb66825114024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Books: 100%|██████████| 302/302 [02:55<00:00,  1.72sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029716086b0141249612321a40c29577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Kindle_Store: 100%|██████████| 127/127 [01:10<00:00,  1.81sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9034b41bc6444c478a74222229f85c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Musical_Instruments: 100%|██████████| 1/1 [00:00<00:00,  1.77sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda932a57d8d41bd8ef9d1e5c83732fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Video_Games: 100%|██████████| 1/1 [00:00<00:00,  1.76sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_fashion:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_fashion/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211c223a17d846a1afb542df92e6cd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->amazon_fashion: 100%|██████████| 1/1 [00:00<00:00,  1.68sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Books): 0.0318\n",
      "Validity@1 (Books): 0.3008, invalid entries: 330 / 472\n",
      "Test details saved to slora_test_out/Books/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Books CONF_THRESHOLD=0.6\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Books\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Books.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Books\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Books/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Books\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Books: 100%|██████████| 472/472 [00:04<00:00, 95.14batch/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Books. Samples: 472\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfd5a38ba694aff9497dc573c064369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Appliances: 100%|██████████| 131/131 [01:12<00:00,  1.82sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Books:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Books/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda8210ba79c47b2bba269c46e7e1f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Books: 100%|██████████| 253/253 [02:20<00:00,  1.80sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd6e3f4e25846f88a9345c03237e47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Kindle_Store: 100%|██████████| 86/86 [00:47<00:00,  1.81sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e928dfe941d0414d8c264c16589a1f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Musical_Instruments: 100%|██████████| 1/1 [00:00<00:00,  1.78sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3573f2b2dd647678d0218b9499e5612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Video_Games: 100%|██████████| 1/1 [00:00<00:00,  1.76sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Books): 0.0318\n",
      "Validity@1 (Books): 0.3008, invalid entries: 330 / 472\n",
      "Test details saved to slora_test_out/Books/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Books CONF_THRESHOLD=0.7\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Books\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Books.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Books\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Books/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Books\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Books: 100%|██████████| 472/472 [00:04<00:00, 95.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Books. Samples: 472\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0d20d7bfe7473a8f32c70b268750a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Appliances: 100%|██████████| 231/231 [02:08<00:00,  1.80sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Books:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Books/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97529e87f94645d291521b2a1c274381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Books: 100%|██████████| 190/190 [01:51<00:00,  1.71sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd62f5c49e84bb1aeefed4ec0416ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Kindle_Store: 100%|██████████| 49/49 [00:27<00:00,  1.79sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f843cee9fdb045a3b913d9e56de674e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Musical_Instruments: 100%|██████████| 1/1 [00:00<00:00,  1.76sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38dc1d72ed14945afabba99c2a857e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Video_Games: 100%|██████████| 1/1 [00:00<00:00,  1.72sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Books): 0.0318\n",
      "Validity@1 (Books): 0.3008, invalid entries: 330 / 472\n",
      "Test details saved to slora_test_out/Books/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Books CONF_THRESHOLD=0.8\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Books\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Books.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Books\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Books/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Books\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Books: 100%|██████████| 472/472 [00:04<00:00, 96.45batch/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Books. Samples: 472\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a906437f5b4445875bbc81f1a20dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Appliances: 100%|██████████| 312/312 [02:52<00:00,  1.81sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Books:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Books/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ac1808f7f745dfb33613afa90928f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Books: 100%|██████████| 135/135 [01:17<00:00,  1.73sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e77dae1d874ff9bd3d10be6dbbeded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Kindle_Store: 100%|██████████| 24/24 [00:13<00:00,  1.84sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043c8bed9437429bb91e7cb6145b111e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Musical_Instruments: 100%|██████████| 1/1 [00:00<00:00,  1.79sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Books): 0.0318\n",
      "Validity@1 (Books): 0.3008, invalid entries: 330 / 472\n",
      "Test details saved to slora_test_out/Books/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Books CONF_THRESHOLD=0.9\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Books\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Books.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Books\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Books/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Books\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Books: 100%|██████████| 472/472 [00:04<00:00, 94.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Books. Samples: 472\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16da50b20a548369dec68fbf91fecae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Appliances: 100%|██████████| 392/392 [03:36<00:00,  1.81sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Books:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Books/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4adc63f7c7405d932c1e30ec757d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Books: 100%|██████████| 72/72 [00:41<00:00,  1.72sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Kindle_Store:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Kindle_Store/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609d330d341e417cbea03a3f00dd8b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Kindle_Store: 100%|██████████| 7/7 [00:04<00:00,  1.72sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Musical_Instruments:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Musical_Instruments/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Books/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7462ce6881a42d7ba9dc050366245d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Books->Musical_Instruments: 100%|██████████| 1/1 [00:00<00:00,  1.75sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Books): 0.0318\n",
      "Validity@1 (Books): 0.3008, invalid entries: 330 / 472\n",
      "Test details saved to slora_test_out/Books/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] done for Books: 7 thresholds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Threshold sweep for Books (sLoRA: vision routed, LM fixed)\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "if 'threshold_sweeps' not in globals():\n",
    "    threshold_sweeps = {}\n",
    "\n",
    "category = \"Books\"\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "rows = []\n",
    "\n",
    "for tau in thresholds:\n",
    "    CONF_THRESHOLD = tau\n",
    "    print(f\"[SWEEP] category={category} CONF_THRESHOLD={CONF_THRESHOLD:.1f}\")\n",
    "    evaluate_category(category)\n",
    "\n",
    "    test_data_path = DATA_ROOT / category / \"test.jsonl\"\n",
    "    test_data = load_jsonl(test_data_path)\n",
    "    ground_truths = [entry.get('gt_items', []) for entry in test_data]\n",
    "\n",
    "    model_key = 'st' if CANDIDATE_TYPE == 'candidates_st' else 'gpt_large'\n",
    "    recommended_field = 'recommended_st' if model_key == 'st' else f\"recommended_{model_key}\"\n",
    "    out_file = Path(f\"./slora_test_out/{category}\") / f\"test_results_{CANDIDATE_TYPE}_router_top3_vl.jsonl\"\n",
    "\n",
    "    results = load_jsonl(out_file)\n",
    "    recommended_ids = [entry.get(recommended_field) for entry in results]\n",
    "    recall = evaluate_recall_at_k(recommended_ids, ground_truths, k=1)\n",
    "    validity, _, _ = check_validity(out_file, model_key)\n",
    "\n",
    "    rows.append({\n",
    "        'category': category,\n",
    "        'tau': tau,\n",
    "        'recall': recall,\n",
    "        'validity': validity,\n",
    "    })\n",
    "\n",
    "threshold_sweeps[category] = rows\n",
    "print(f\"[SWEEP] done for {category}: {len(rows)} thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04e3dd96-11a8-4c25-b64b-dc14d847ec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SWEEP] category=Toys_and_Games CONF_THRESHOLD=0.3\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Toys_and_Games\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Toys_and_Games.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Toys_and_Games\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Toys_and_Games/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Toys_and_Games\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Toys_and_Games: 100%|██████████| 192/192 [00:02<00:00, 79.88batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Toys_and_Games. Samples: 192\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7342b0c64d3c44ed9f2ee664d1f2cf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Appliances: 100%|██████████| 10/10 [00:05<00:00,  1.71sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Electronics:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Electronics/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c844a5a8374bafbca0735129cb9d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Electronics: 100%|██████████| 1/1 [00:00<00:00,  1.62sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763962e1491f4d4ba836041a0e3a4617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Handmade_Products: 100%|██████████| 4/4 [00:02<00:00,  1.56sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Industrial_and_Scientific:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Industrial_and_Scientific/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fe0a39959d493096106880f8d83aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Industrial_and_Scientific: 100%|██████████| 1/1 [00:00<00:00,  1.60sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcffd6ab53b422b8c25efa3d9f74126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Movies_and_TV: 100%|██████████| 6/6 [00:03<00:00,  1.68sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Office_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Office_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c40e2bccf974d00b8d40f9f41c80bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Office_Products: 100%|██████████| 1/1 [00:00<00:00,  1.63sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Sports_and_Outdoors:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Sports_and_Outdoors/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79280c9bb8f483799d2d857cc68c8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Sports_and_Outdoors: 100%|██████████| 1/1 [00:00<00:00,  1.68sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Toys_and_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Toys_and_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4264ab037d714de083ab7268e7d14df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Toys_and_Games: 100%|██████████| 148/148 [01:34<00:00,  1.57sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b13e003b9e4fd59e6fbe7ef3c713be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Video_Games: 100%|██████████| 52/52 [00:33<00:00,  1.56sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_fashion:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_fashion/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed7990254ba40d58f8d4bd41796b64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->amazon_fashion: 100%|██████████| 2/2 [00:01<00:00,  1.69sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Toys_and_Games): 0.3229\n",
      "Validity@1 (Toys_and_Games): 1.0000, invalid entries: 0 / 192\n",
      "Test details saved to slora_test_out/Toys_and_Games/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Toys_and_Games CONF_THRESHOLD=0.4\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Toys_and_Games\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Toys_and_Games.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Toys_and_Games\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Toys_and_Games/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Toys_and_Games\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Toys_and_Games: 100%|██████████| 192/192 [00:02<00:00, 79.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Toys_and_Games. Samples: 192\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1283d9be6d9e4253a289e92b11c6d74b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Appliances: 100%|██████████| 22/22 [00:12<00:00,  1.72sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5360937c20ee4bc0bbdb39dcda8f5bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Handmade_Products: 100%|██████████| 3/3 [00:01<00:00,  1.61sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7247d110f8324a5990a1ec7ff4ca6c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Movies_and_TV: 100%|██████████| 5/5 [00:02<00:00,  1.74sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Toys_and_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Toys_and_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f207cc37a13a450c857721ef5a3e4923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Toys_and_Games: 100%|██████████| 130/130 [01:20<00:00,  1.62sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbcffff0adc48cf942be912319c2cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Video_Games: 100%|██████████| 42/42 [00:25<00:00,  1.62sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_fashion:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_fashion/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c435329decc4186bc35b02518a29bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->amazon_fashion: 100%|██████████| 1/1 [00:00<00:00,  1.60sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Toys_and_Games): 0.3229\n",
      "Validity@1 (Toys_and_Games): 1.0000, invalid entries: 0 / 192\n",
      "Test details saved to slora_test_out/Toys_and_Games/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Toys_and_Games CONF_THRESHOLD=0.5\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Toys_and_Games\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Toys_and_Games.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Toys_and_Games\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Toys_and_Games/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Toys_and_Games\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Toys_and_Games: 100%|██████████| 192/192 [00:02<00:00, 78.89batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Toys_and_Games. Samples: 192\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db32014bdf3f4a549428506cb4a9ace2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Appliances: 100%|██████████| 37/37 [00:21<00:00,  1.72sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba607897f4764a089ec85918889e19f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Handmade_Products: 100%|██████████| 3/3 [00:01<00:00,  1.55sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c710548dd94d31a7372c50a0d4fded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Movies_and_TV: 100%|██████████| 3/3 [00:01<00:00,  1.75sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Toys_and_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Toys_and_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3401a039768481e8a9e230fe4031ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Toys_and_Games: 100%|██████████| 116/116 [01:11<00:00,  1.62sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c97d0dee375485595bf2c261589f919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Video_Games: 100%|██████████| 33/33 [00:20<00:00,  1.62sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Toys_and_Games): 0.3229\n",
      "Validity@1 (Toys_and_Games): 1.0000, invalid entries: 0 / 192\n",
      "Test details saved to slora_test_out/Toys_and_Games/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Toys_and_Games CONF_THRESHOLD=0.6\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Toys_and_Games\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Toys_and_Games.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Toys_and_Games\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Toys_and_Games/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Toys_and_Games\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Toys_and_Games: 100%|██████████| 192/192 [00:02<00:00, 80.23batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Toys_and_Games. Samples: 192\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5d5d9268b040af971d3eadd46ca533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Appliances: 100%|██████████| 62/62 [00:36<00:00,  1.68sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d38c19ca94546de81e4928781ddc146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Handmade_Products: 100%|██████████| 2/2 [00:01<00:00,  1.54sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf27731b451b43c48e6a118975673950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Movies_and_TV: 100%|██████████| 1/1 [00:00<00:00,  1.64sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Toys_and_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Toys_and_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550f9bd49f374325a14538b25051457e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Toys_and_Games: 100%|██████████| 98/98 [01:04<00:00,  1.52sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6283eaa4e6eb4216997334687cccaee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Video_Games: 100%|██████████| 29/29 [00:17<00:00,  1.63sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Toys_and_Games): 0.3229\n",
      "Validity@1 (Toys_and_Games): 1.0000, invalid entries: 0 / 192\n",
      "Test details saved to slora_test_out/Toys_and_Games/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Toys_and_Games CONF_THRESHOLD=0.7\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Toys_and_Games\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Toys_and_Games.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Toys_and_Games\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Toys_and_Games/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Toys_and_Games\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Toys_and_Games: 100%|██████████| 192/192 [00:02<00:00, 78.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Toys_and_Games. Samples: 192\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=88\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d82196ffe0443381b9af8a632f865e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Appliances: 100%|██████████| 88/88 [00:52<00:00,  1.67sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448b2443e31d4909bc815ae32fac949e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Handmade_Products: 100%|██████████| 2/2 [00:01<00:00,  1.56sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Movies_and_TV:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Movies_and_TV/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ee015b045d4badb921da9f972ff289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Movies_and_TV: 100%|██████████| 1/1 [00:00<00:00,  1.71sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Toys_and_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Toys_and_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8235a84b4f894b2a8429389e02d01d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Toys_and_Games: 100%|██████████| 79/79 [00:50<00:00,  1.57sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a99466c59dc4a6482f21d743337edc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Video_Games: 100%|██████████| 22/22 [00:13<00:00,  1.64sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Toys_and_Games): 0.3229\n",
      "Validity@1 (Toys_and_Games): 1.0000, invalid entries: 0 / 192\n",
      "Test details saved to slora_test_out/Toys_and_Games/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Toys_and_Games CONF_THRESHOLD=0.8\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Toys_and_Games\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Toys_and_Games.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Toys_and_Games\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Toys_and_Games/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Toys_and_Games\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Toys_and_Games: 100%|██████████| 192/192 [00:02<00:00, 77.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Toys_and_Games. Samples: 192\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39034720bc944e9cbf522a9c43676ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Appliances: 100%|██████████| 110/110 [01:05<00:00,  1.67sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Handmade_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Handmade_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401967e66a8a4fffbe8eb65d971c801d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Handmade_Products: 100%|██████████| 1/1 [00:00<00:00,  1.38sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Toys_and_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Toys_and_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434b4cb3aed44578a71c66183807a121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Toys_and_Games: 100%|██████████| 66/66 [00:40<00:00,  1.62sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cf47395f76495fbf4425961c4505f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Video_Games: 100%|██████████| 15/15 [00:09<00:00,  1.64sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Toys_and_Games): 0.3229\n",
      "Validity@1 (Toys_and_Games): 1.0000, invalid entries: 0 / 192\n",
      "Test details saved to slora_test_out/Toys_and_Games/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Toys_and_Games CONF_THRESHOLD=0.9\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Toys_and_Games\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Toys_and_Games.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Toys_and_Games\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Toys_and_Games/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Toys_and_Games\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Toys_and_Games: 100%|██████████| 192/192 [00:02<00:00, 79.97batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Toys_and_Games. Samples: 192\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b06e6fa90943359376a24a721cff72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Appliances: 100%|██████████| 147/147 [01:29<00:00,  1.65sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Toys_and_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Toys_and_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890b7927d41644fdb958010438e11162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Toys_and_Games: 100%|██████████| 33/33 [00:20<00:00,  1.61sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Video_Games:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Video_Games/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Toys_and_Games/prompt_tuning/trained_lora_adapter\n",
      "  samples=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6879c892a8de414090d486146ce0e295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Toys_and_Games->Video_Games: 100%|██████████| 12/12 [00:07<00:00,  1.63sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Toys_and_Games): 0.3177\n",
      "Validity@1 (Toys_and_Games): 1.0000, invalid entries: 0 / 192\n",
      "Test details saved to slora_test_out/Toys_and_Games/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] done for Toys_and_Games: 7 thresholds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Threshold sweep for Toys_and_Games (sLoRA: vision routed, LM fixed)\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "if 'threshold_sweeps' not in globals():\n",
    "    threshold_sweeps = {}\n",
    "\n",
    "category = \"Toys_and_Games\"\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "rows = []\n",
    "\n",
    "for tau in thresholds:\n",
    "    CONF_THRESHOLD = tau\n",
    "    print(f\"[SWEEP] category={category} CONF_THRESHOLD={CONF_THRESHOLD:.1f}\")\n",
    "    evaluate_category(category)\n",
    "\n",
    "    test_data_path = DATA_ROOT / category / \"test.jsonl\"\n",
    "    test_data = load_jsonl(test_data_path)\n",
    "    ground_truths = [entry.get('gt_items', []) for entry in test_data]\n",
    "\n",
    "    model_key = 'st' if CANDIDATE_TYPE == 'candidates_st' else 'gpt_large'\n",
    "    recommended_field = 'recommended_st' if model_key == 'st' else f\"recommended_{model_key}\"\n",
    "    out_file = Path(f\"./slora_test_out/{category}\") / f\"test_results_{CANDIDATE_TYPE}_router_top3_vl.jsonl\"\n",
    "\n",
    "    results = load_jsonl(out_file)\n",
    "    recommended_ids = [entry.get(recommended_field) for entry in results]\n",
    "    recall = evaluate_recall_at_k(recommended_ids, ground_truths, k=1)\n",
    "    validity, _, _ = check_validity(out_file, model_key)\n",
    "\n",
    "    rows.append({\n",
    "        'category': category,\n",
    "        'tau': tau,\n",
    "        'recall': recall,\n",
    "        'validity': validity,\n",
    "    })\n",
    "\n",
    "threshold_sweeps[category] = rows\n",
    "print(f\"[SWEEP] done for {category}: {len(rows)} thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "365fb0ae-42c4-4874-8277-6f4d0cfcae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SWEEP] category=Appliances CONF_THRESHOLD=0.3\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Appliances\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Appliances.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Appliances\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Appliances/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Appliances\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Appliances: 100%|██████████| 230/230 [00:02<00:00, 93.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Appliances. Samples: 230\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f2f663c7c946d99989036dec22b409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Appliances: 100%|██████████| 220/220 [02:10<00:00,  1.69sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Automotive:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Automotive/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a953c0cb354d83a0e5b1f177b3e4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Automotive: 100%|██████████| 1/1 [00:00<00:00,  1.68sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Baby_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Baby_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5e347feaa34a879029a1503d0af2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Baby_Products: 100%|██████████| 1/1 [00:00<00:00,  1.56sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Electronics:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Electronics/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56d7384236b4eef9b9b11fa3e6f5719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Electronics: 100%|██████████| 1/1 [00:00<00:00,  1.58sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Grocery_and_Gourmet_Food:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Grocery_and_Gourmet_Food/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3364d8ec83174089911af86485f94b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Grocery_and_Gourmet_Food: 100%|██████████| 1/1 [00:00<00:00,  1.56sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Industrial_and_Scientific:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Industrial_and_Scientific/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2011a7a67a44b7cbdc35c9b091c3f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Industrial_and_Scientific: 100%|██████████| 1/1 [00:00<00:00,  1.58sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Office_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Office_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd8ca910501476ea71b1b09df906a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Office_Products: 100%|██████████| 1/1 [00:00<00:00,  1.64sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c5ff1ba24243cfb4ef4d882e4a7b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Pet_Supplies: 100%|██████████| 3/3 [00:01<00:00,  1.59sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15fb6652f594a10ba31cc53907214eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->amazon_home: 100%|██████████| 7/7 [00:04<00:00,  1.61sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Appliances): 0.3478\n",
      "Validity@1 (Appliances): 0.9957, invalid entries: 1 / 230\n",
      "Test details saved to slora_test_out/Appliances/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Appliances CONF_THRESHOLD=0.4\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Appliances\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Appliances.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Appliances\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Appliances/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Appliances\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Appliances: 100%|██████████| 230/230 [00:02<00:00, 96.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Appliances. Samples: 230\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4565141334384d6ca7c417f459cf12d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Appliances: 100%|██████████| 220/220 [02:10<00:00,  1.69sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Automotive:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Automotive/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c083c316bc43a89a54f6c83d170d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Automotive: 100%|██████████| 1/1 [00:00<00:00,  1.64sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Baby_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Baby_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62ba900ac774cee9377c229b715a42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Baby_Products: 100%|██████████| 1/1 [00:00<00:00,  1.44sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Industrial_and_Scientific:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Industrial_and_Scientific/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e507cead8d7047229d77d0ad0dd9e5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Industrial_and_Scientific: 100%|██████████| 1/1 [00:00<00:00,  1.64sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Office_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Office_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd89d68469f4ecfa2676141ef5ec040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Office_Products: 100%|██████████| 1/1 [00:00<00:00,  1.54sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78481ecdc7b24f10938dacd853fd6355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Pet_Supplies: 100%|██████████| 3/3 [00:01<00:00,  1.65sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bd4a9b54f24cfeb1472992fb2ad08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->amazon_home: 100%|██████████| 3/3 [00:01<00:00,  1.51sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Appliances): 0.3478\n",
      "Validity@1 (Appliances): 0.9957, invalid entries: 1 / 230\n",
      "Test details saved to slora_test_out/Appliances/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Appliances CONF_THRESHOLD=0.5\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Appliances\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Appliances.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Appliances\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Appliances/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Appliances\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Appliances: 100%|██████████| 230/230 [00:02<00:00, 95.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Appliances. Samples: 230\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac72aaad2f144b7ac56caac61e0b4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Appliances: 100%|██████████| 222/222 [02:12<00:00,  1.67sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Automotive:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Automotive/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c252e3897046f7840dbd903b972d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Automotive: 100%|██████████| 1/1 [00:00<00:00,  1.66sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Baby_Products:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Baby_Products/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65eb30ec2390456fbc6dc3f344436386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Baby_Products: 100%|██████████| 1/1 [00:00<00:00,  1.47sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Industrial_and_Scientific:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Industrial_and_Scientific/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2d8dc2e5794ea89efb4af1a7f0adbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Industrial_and_Scientific: 100%|██████████| 1/1 [00:00<00:00,  1.62sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ee308e22c146b694465a7cdc278586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Pet_Supplies: 100%|██████████| 2/2 [00:01<00:00,  1.62sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2057bc353e943e8acc626e2bb2050db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->amazon_home: 100%|██████████| 3/3 [00:02<00:00,  1.49sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Appliances): 0.3478\n",
      "Validity@1 (Appliances): 0.9957, invalid entries: 1 / 230\n",
      "Test details saved to slora_test_out/Appliances/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Appliances CONF_THRESHOLD=0.6\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Appliances\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Appliances.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Appliances\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Appliances/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Appliances\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Appliances: 100%|██████████| 230/230 [00:02<00:00, 90.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Appliances. Samples: 230\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd08822405254685b92ad26415f2447c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Appliances: 100%|██████████| 226/226 [02:15<00:00,  1.66sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for Pet_Supplies:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Pet_Supplies/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316a5d9fd7e04922a835d979ec9dd79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Pet_Supplies: 100%|██████████| 1/1 [00:00<00:00,  1.50sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a11f752beb4375baa47b296f4c8427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->amazon_home: 100%|██████████| 3/3 [00:01<00:00,  1.50sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Appliances): 0.3478\n",
      "Validity@1 (Appliances): 0.9957, invalid entries: 1 / 230\n",
      "Test details saved to slora_test_out/Appliances/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Appliances CONF_THRESHOLD=0.7\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Appliances\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Appliances.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Appliances\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Appliances/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Appliances\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Appliances: 100%|██████████| 230/230 [00:02<00:00, 92.59batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Appliances. Samples: 230\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3b2f3e65f94cc984b96ade1ad41b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Appliances: 100%|██████████| 229/229 [02:17<00:00,  1.67sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Load model for amazon_home:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/amazon_home/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9678c77f5b44c8910223419e319214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->amazon_home: 100%|██████████| 1/1 [00:00<00:00,  1.54sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Appliances): 0.3478\n",
      "Validity@1 (Appliances): 0.9957, invalid entries: 1 / 230\n",
      "Test details saved to slora_test_out/Appliances/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Appliances CONF_THRESHOLD=0.8\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Appliances\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Appliances.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Appliances\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Appliances/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Appliances\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Appliances: 100%|██████████| 230/230 [00:02<00:00, 92.49batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Appliances. Samples: 230\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9810f53448ee4dd3a6e17f3bcf9500b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Appliances: 100%|██████████| 230/230 [02:26<00:00,  1.57sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Appliances): 0.3478\n",
      "Validity@1 (Appliances): 0.9957, invalid entries: 1 / 230\n",
      "Test details saved to slora_test_out/Appliances/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] category=Appliances CONF_THRESHOLD=0.9\n",
      "[DEBUG] LM_FIXED_DIR: /root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "\n",
      "========================================\n",
      "[DEBUG] Start category: Appliances\n",
      "ITEM_META_PATH: /root/autodl-tmp/lavic/data/item2meta_train_Appliances.with_desc.json\n",
      "IMAGE_DIR: /root/autodl-tmp/lavic/data/train_images/Appliances\n",
      "TEST_DATA_PATH: /root/autodl-tmp/lavic/data/Appliances/test.jsonl\n",
      "FINETUNE_OUTPUT_DIR: ./slora_test_out/Appliances\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Routing Appliances: 100%|██████████| 230/230 [00:02<00:00, 95.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Routing complete for Appliances. Samples: 230\n",
      "[DEBUG] Load model for Appliances:\n",
      "  vision=/root/autodl-tmp/lavic/src/out_distilled/Appliances/lora_adapter_best\n",
      "  lm=/root/autodl-tmp/lavic/src/out_finetuned/Appliances/prompt_tuning/trained_lora_adapter\n",
      "  samples=230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b795b642d4484e72bcf719950f34ae58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Appliances->Appliances: 100%|██████████| 230/230 [02:17<00:00,  1.67sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Recall@1 (Appliances): 0.3478\n",
      "Validity@1 (Appliances): 0.9957, invalid entries: 1 / 230\n",
      "Test details saved to slora_test_out/Appliances/test_results_candidates_st_router_top3_vl.jsonl\n",
      "[SWEEP] done for Appliances: 7 thresholds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Threshold sweep for Appliances (sLoRA: vision routed, LM fixed)\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "if 'threshold_sweeps' not in globals():\n",
    "    threshold_sweeps = {}\n",
    "\n",
    "category = \"Appliances\"\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "rows = []\n",
    "\n",
    "for tau in thresholds:\n",
    "    CONF_THRESHOLD = tau\n",
    "    print(f\"[SWEEP] category={category} CONF_THRESHOLD={CONF_THRESHOLD:.1f}\")\n",
    "    evaluate_category(category)\n",
    "\n",
    "    test_data_path = DATA_ROOT / category / \"test.jsonl\"\n",
    "    test_data = load_jsonl(test_data_path)\n",
    "    ground_truths = [entry.get('gt_items', []) for entry in test_data]\n",
    "\n",
    "    model_key = 'st' if CANDIDATE_TYPE == 'candidates_st' else 'gpt_large'\n",
    "    recommended_field = 'recommended_st' if model_key == 'st' else f\"recommended_{model_key}\"\n",
    "    out_file = Path(f\"./slora_test_out/{category}\") / f\"test_results_{CANDIDATE_TYPE}_router_top3_vl.jsonl\"\n",
    "\n",
    "    results = load_jsonl(out_file)\n",
    "    recommended_ids = [entry.get(recommended_field) for entry in results]\n",
    "    recall = evaluate_recall_at_k(recommended_ids, ground_truths, k=1)\n",
    "    validity, _, _ = check_validity(out_file, model_key)\n",
    "\n",
    "    rows.append({\n",
    "        'category': category,\n",
    "        'tau': tau,\n",
    "        'recall': recall,\n",
    "        'validity': validity,\n",
    "    })\n",
    "\n",
    "threshold_sweeps[category] = rows\n",
    "print(f\"[SWEEP] done for {category}: {len(rows)} thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "136e7e18-4c09-4024-b0b7-6a0548f71a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\ttau\trecall\tvalidity\n",
      "Appliances\t0.3\t0.3478\t0.9957\n",
      "Appliances\t0.4\t0.3478\t0.9957\n",
      "Appliances\t0.5\t0.3478\t0.9957\n",
      "Appliances\t0.6\t0.3478\t0.9957\n",
      "Appliances\t0.7\t0.3478\t0.9957\n",
      "Appliances\t0.8\t0.3478\t0.9957\n",
      "Appliances\t0.9\t0.3478\t0.9957\n",
      "Books\t0.3\t0.0318\t0.3008\n",
      "Books\t0.4\t0.0318\t0.3008\n",
      "Books\t0.5\t0.0318\t0.3008\n",
      "Books\t0.6\t0.0318\t0.3008\n",
      "Books\t0.7\t0.0318\t0.3008\n",
      "Books\t0.8\t0.0318\t0.3008\n",
      "Books\t0.9\t0.0318\t0.3008\n",
      "Toys_and_Games\t0.3\t0.3229\t1.0000\n",
      "Toys_and_Games\t0.4\t0.3229\t1.0000\n",
      "Toys_and_Games\t0.5\t0.3229\t1.0000\n",
      "Toys_and_Games\t0.6\t0.3229\t1.0000\n",
      "Toys_and_Games\t0.7\t0.3229\t1.0000\n",
      "Toys_and_Games\t0.8\t0.3229\t1.0000\n",
      "Toys_and_Games\t0.9\t0.3177\t1.0000\n",
      "\n",
      "Best tau per category (by recall):\n",
      "category\ttau\trecall\tvalidity\n",
      "Appliances\t0.3\t0.3478\t0.9957\n",
      "Books\t0.3\t0.0318\t0.3008\n",
      "Toys_and_Games\t0.3\t0.3229\t1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize sweeps: table + line plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'threshold_sweeps' not in globals() or not threshold_sweeps:\n",
    "    raise RuntimeError(\"threshold_sweeps is empty. Run the per-category sweep cells first.\")\n",
    "\n",
    "rows = []\n",
    "for cat, items in threshold_sweeps.items():\n",
    "    rows.extend(items)\n",
    "\n",
    "if not rows:\n",
    "    raise RuntimeError(\"No sweep results found.\")\n",
    "\n",
    "# Table (sorted)\n",
    "rows_sorted = sorted(rows, key=lambda r: (r['category'], r['tau']))\n",
    "print(\"category\\ttau\\trecall\\tvalidity\")\n",
    "for r in rows_sorted:\n",
    "    print(f\"{r['category']}\\t{r['tau']:.1f}\\t{r['recall']:.4f}\\t{r['validity']:.4f}\")\n",
    "\n",
    "# Best tau per category (by recall)\n",
    "best_by_cat = {}\n",
    "for r in rows_sorted:\n",
    "    key = r['category']\n",
    "    if key not in best_by_cat or r['recall'] > best_by_cat[key]['recall']:\n",
    "        best_by_cat[key] = r\n",
    "print(\"\\nBest tau per category (by recall):\")\n",
    "print(\"category\\ttau\\trecall\\tvalidity\")\n",
    "for key in sorted(best_by_cat.keys()):\n",
    "    r = best_by_cat[key]\n",
    "    print(f\"{r['category']}\\t{r['tau']:.1f}\\t{r['recall']:.4f}\\t{r['validity']:.4f}\")\n",
    "\n",
    "# Line plot: recall vs tau\n",
    "plt.figure(figsize=(7, 4))\n",
    "for cat in sorted({r['category'] for r in rows_sorted}):\n",
    "    sub = [r for r in rows_sorted if r['category'] == cat]\n",
    "    taus = [r['tau'] for r in sub]\n",
    "    recalls = [r['recall'] for r in sub]\n",
    "    plt.plot(taus, recalls, marker='o', label=cat)\n",
    "\n",
    "plt.title('Recall@1 vs CONF_THRESHOLD (sLoRA)')\n",
    "plt.xlabel('CONF_THRESHOLD (tau)')\n",
    "plt.ylabel('Recall@1')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc21ccbb-11eb-4ea5-b409-310268eb89e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
